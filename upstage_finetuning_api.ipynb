{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEJmh-uYQ-IH"
      },
      "source": [
        "# Upstage Fine-tuning API - Jeju Island AI-powered travel planner\n",
        "\n",
        "Code authored by: Jonathan Siew Zunxian\n",
        "\n",
        "Template by: Shawhin Talebi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/fine-tuning/ft-example.ipynb\n",
        "2. https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/ai-assistant-openai/finetuning-api.ipynb"
      ],
      "metadata": {
        "id": "DUcbkDzEVd7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Set Up: (done)"
      ],
      "metadata": {
        "id": "JyS5z5NXVXOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy16jslFRsXc",
        "outputId": "3c88772d-3350-4af4-ba4f-67ed9d5065d2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.37.2-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.1/337.1 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import csv\n",
        "import json\n",
        "import random"
      ],
      "metadata": {
        "id": "jmIGxXCkTS1o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojWXKkjGQ-IJ"
      },
      "source": [
        "### Create client: (done)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "api_key_value = userdata.get('Upstage')\n",
        "client = OpenAI(\n",
        "    api_key=api_key_value,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")"
      ],
      "metadata": {
        "id": "GAdWweDbM-D8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JElWG6PgQ-IJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key_value=userdata.get('Upstage')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=api_key_value,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSdyZJYJQ-IK"
      },
      "source": [
        "### Prepare training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P2P0Ef2zQ-IK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd2ea8f-6836-40a1-d728-0c8d4cb2bde4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "question_list = []\n",
        "response_list = []\n",
        "\n",
        "# Use the correct path to your CSV file\n",
        "with open('Jeju Island Comprehensive FAQ.csv', mode='r') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "\n",
        "    # Skip the header row if present\n",
        "    next(csv_reader, None)\n",
        "\n",
        "    for line in csv_reader:\n",
        "        question_list.append(line[0])\n",
        "        response_list.append(line[1])\n",
        "\n",
        "len(question_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oxFAWmJUQ-IK"
      },
      "outputs": [],
      "source": [
        "# Few-shot instructions string\n",
        "instructions_string_few_shot = \"\"\"TourismGPT, acting as a virtual guide to Jeju Island, uses clear, accessible language, offering more technical depth upon request. \\\n",
        "It aptly reacts to feedback and ends its messages with '–AINewbiesTourismGPT'. Responses are tailored to the length and style of the viewer comments, ensuring a natural and engaging interaction.\n",
        "\n",
        "Here are examples of TourismGPT responding to viewer comments.\n",
        "\n",
        "Question: What is the size of Jeju Island?\n",
        "AINewbiesTourismGPT: Jeju Island measures about 73 km by 31 km. - AINewbiesTourismGPT\n",
        "\n",
        "Question: What is the climate like in Jeju?\n",
        "AINewbiesTourismGPT: Jeju has a mild climate, rarely dropping below zero in the winter. - AINewbiesTourismGPT\n",
        "\"\"\"\n",
        "\n",
        "# Create examples list\n",
        "example_list = []\n",
        "for i in range(len(question_list)):\n",
        "    system_dict = {\"role\": \"system\", \"content\": instructions_string_few_shot}\n",
        "    user_dict = {\"role\": \"user\", \"content\": question_list[i]}\n",
        "    assistant_dict = {\"role\": \"assistant\", \"content\": response_list[i]}\n",
        "\n",
        "    messages_list = [system_dict, user_dict, assistant_dict]\n",
        "\n",
        "    example_list.append({\"messages\": messages_list})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LCM3kOODQ-IK"
      },
      "outputs": [],
      "source": [
        "validation_index_list = random.sample(range(0, len(example_list)-1), 9)\n",
        "\n",
        "validation_data_list = [example_list[index] for index in validation_index_list]\n",
        "\n",
        "for example in validation_data_list:\n",
        "    example_list.remove(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TM2aTigpQ-IL"
      },
      "outputs": [],
      "source": [
        "with open('training-data.jsonl', 'w') as training_file:\n",
        "    for example in example_list:\n",
        "        json.dump(example, training_file)\n",
        "        training_file.write('\\n')\n",
        "\n",
        "with open('validation-data.jsonl', 'w') as validation_file:\n",
        "    for example in validation_data_list:\n",
        "        json.dump(example, validation_file)\n",
        "        validation_file.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxc3ddiQ-IL"
      },
      "source": [
        "### Upload training examples to Upstage API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import userdata\n",
        "api_key_value=userdata.get('Upstage')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=api_key_value,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")\n",
        "\n",
        "# Make sure the files exist in the specified path\n",
        "training_file_path = \"training-data.jsonl\"\n",
        "validation_file_path = \"validation-data.jsonl\"\n",
        "\n",
        "# Create the training file\n",
        "training_file = client.files.create(\n",
        "    file=open(training_file_path, \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "# Create the validation file\n",
        "validation_file = client.files.create(\n",
        "    file=open(validation_file_path, \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "\n",
        "print(f\"Training file uploaded: {training_file.id}\")\n",
        "print(f\"Validation file uploaded: {validation_file.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "kapsS9wfNFbg",
        "outputId": "daa4568e-7c6e-4a46-9d4f-746a4c7b6bef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "404 page not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-6cea33a3dcb8>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Create the training file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m training_file = client.files.create(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mpurpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fine-tune\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/files.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, file, purpose, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# multipart/form-data; boundary=---abc--\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"multipart/form-data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_headers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;34m\"/files\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         )\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 942\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    943\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: 404 page not found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxkdpKOjQ-IL"
      },
      "source": [
        "### Create a fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WOI19YUQ-IL"
      },
      "outputs": [],
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "    training_file = training_file.id,\n",
        "    validation_file = validation_file.id,\n",
        "    suffix = \"AINewbiesTourismGPT\",\n",
        "    model = \"solar-1-mini-chat\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzcS-eyrQ-IL"
      },
      "source": [
        "### Use fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLbCXVAYQ-IL"
      },
      "outputs": [],
      "source": [
        "test_comment = \"Great content, thank you!\"\n",
        "test_comment = \"I am typing this after watching half of the video as I am already amazed with the clarity of explanation. exceptional.\"\n",
        "test_comment = \"What is fat-tailedness?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"ft:upstage-3.5-turbo-0613:personal:shawgpt:8mUeVreo\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": intstructions_string_few_shot},\n",
        "    {\"role\": \"user\", \"content\": test_comment}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(dict(response)['choices'][0]['message']['content'])\n",
        "\n",
        "# delete file\n",
        "client.files.delete(training_file.id)\n",
        "client.files.delete(validation_file.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X-lRnoZQ-IM"
      },
      "source": [
        "### More resources\n",
        "\n",
        "Upstage Guide: [Insert Upstage Guide URL]\n",
        "Fine-tuning doc: [Insert Fine-tuning Documentation URL]\n",
        "Fine-tuning data prep: [Insert Fine-tuning Data Preparation URL]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}