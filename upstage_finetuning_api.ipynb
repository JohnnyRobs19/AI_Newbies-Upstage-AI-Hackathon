{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEJmh-uYQ-IH"
      },
      "source": [
        "# Upstage Fine-tuning API - Jeju Island AI-powered travel planner\n",
        "\n",
        "Code authored by: Jonathan Siew Zunxian\n",
        "\n",
        "Template by: Shawhin Talebi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/fine-tuning/ft-example.ipynb\n",
        "2. https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/ai-assistant-openai/finetuning-api.ipynb"
      ],
      "metadata": {
        "id": "DUcbkDzEVd7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Set Up: (done)"
      ],
      "metadata": {
        "id": "JyS5z5NXVXOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy16jslFRsXc",
        "outputId": "ba7ee287-a2ae-4c49-b9b5-c573b308eebc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.37.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.37.1-py3-none-any.whl (337 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.37.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "csf4r1C-Q-II"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "import random"
      ],
      "metadata": {
        "id": "jmIGxXCkTS1o"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojWXKkjGQ-IJ"
      },
      "source": [
        "### Create client: (done)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JElWG6PgQ-IJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key_value=userdata.get('Upstage')\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=api_key_value,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSdyZJYJQ-IK"
      },
      "source": [
        "### Prepare training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2P0Ef2zQ-IK"
      },
      "outputs": [],
      "source": [
        "comment_list = []\n",
        "response_list = []\n",
        "\n",
        "with open('data/YT-comments.csv', mode ='r') as file:\n",
        "    file = csv.reader(file)\n",
        "\n",
        "    for line in file:\n",
        "        if line[0]=='Comment':\n",
        "            continue\n",
        "        comment_list.append(line[0])\n",
        "        response_list.append(line[1] + \" -ShawGPT\")\n",
        "\n",
        "len(comment_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxFAWmJUQ-IK"
      },
      "outputs": [],
      "source": [
        "example_list = []\n",
        "\n",
        "intstructions_string_few_shot = \"\"\"ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\n",
        "It reacts to feedback aptly and concludes with its signature '–ShawGPT'. \\\n",
        "ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
        "thus keeping the interaction natural and engaging.\n",
        "\n",
        "Here are examples of ShawGPT responding to viewer comments.\n",
        "\n",
        "Viewer comment: This was a very thorough introduction to LLMs and answered many questions I had. Thank you.\n",
        "ShawGPT: Great to hear, glad it was helpful :) -ShawGPT\n",
        "\n",
        "Viewer comment: Epic, very useful for my BCI class\n",
        "ShawGPT: Thanks, glad to hear! -ShawGPT\n",
        "\n",
        "Viewer comment: Honestly the most straightforward explanation I've ever watched. Super excellent work Shaw. Thank you. It's so rare to find good communicators like you!\n",
        "ShawGPT: Thanks, glad it was clear -ShawGPT\"\"\"\n",
        "\n",
        "for i in range(len(comment_list)):\n",
        "    system_dict = {\"role\": \"system\", \"content\": intstructions_string_few_shot}\n",
        "    user_dict = {\"role\": \"user\", \"content\": comment_list[i]}\n",
        "    assistant_dict = {\"role\": \"assistant\", \"content\": response_list[i]}\n",
        "\n",
        "    messages_list = [system_dict, user_dict, assistant_dict]\n",
        "\n",
        "    example_list.append({\"messages\": messages_list})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCM3kOODQ-IK"
      },
      "outputs": [],
      "source": [
        "validation_index_list = random.sample(range(0, len(example_list)-1), 9)\n",
        "\n",
        "validation_data_list = [example_list[index] for index in validation_index_list]\n",
        "\n",
        "for example in validation_data_list:\n",
        "    example_list.remove(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TM2aTigpQ-IL"
      },
      "outputs": [],
      "source": [
        "with open('data/training-data.jsonl', 'w') as training_file:\n",
        "    for example in example_list:\n",
        "        json.dump(example, training_file)\n",
        "        training_file.write('\\n')\n",
        "\n",
        "with open('data/validation-data.jsonl', 'w') as validation_file:\n",
        "    for example in validation_data_list:\n",
        "        json.dump(example, validation_file)\n",
        "        validation_file.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shxc3ddiQ-IL"
      },
      "source": [
        "### Upload training examples to Upstage API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQMPzCyQ-IL"
      },
      "outputs": [],
      "source": [
        "training_file = client.files.create(\n",
        "  file = open(\"data/training-data.jsonl\", \"rb\"),\n",
        "  purpose = \"fine-tune\"\n",
        ")\n",
        "\n",
        "validation_file = client.files.create(\n",
        "  file = open(\"data/validation-data.jsonl\", \"rb\"),\n",
        "  purpose = \"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxkdpKOjQ-IL"
      },
      "source": [
        "### Create a fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WOI19YUQ-IL"
      },
      "outputs": [],
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "    training_file = training_file.id,\n",
        "    validation_file = validation_file.id,\n",
        "    suffix = \"ShawGPT\",\n",
        "    model = \"upstage-3.5-turbo\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzcS-eyrQ-IL"
      },
      "source": [
        "### Use fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLbCXVAYQ-IL"
      },
      "outputs": [],
      "source": [
        "test_comment = \"Great content, thank you!\"\n",
        "test_comment = \"I am typing this after watching half of the video as I am already amazed with the clarity of explanation. exceptional.\"\n",
        "test_comment = \"What is fat-tailedness?\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"ft:upstage-3.5-turbo-0613:personal:shawgpt:8mUeVreo\",\n",
        "    messages=[\n",
        "    {\"role\": \"system\", \"content\": intstructions_string_few_shot},\n",
        "    {\"role\": \"user\", \"content\": test_comment}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(dict(response)['choices'][0]['message']['content'])\n",
        "\n",
        "# delete file\n",
        "client.files.delete(training_file.id)\n",
        "client.files.delete(validation_file.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X-lRnoZQ-IM"
      },
      "source": [
        "### More resources\n",
        "\n",
        "Upstage Guide: [Insert Upstage Guide URL]\n",
        "Fine-tuning doc: [Insert Fine-tuning Documentation URL]\n",
        "Fine-tuning data prep: [Insert Fine-tuning Data Preparation URL]"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}